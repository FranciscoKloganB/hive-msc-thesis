%% fsip2pnupsg.tex
%% V0.1
%% 2019/11/27
%% by Francisco Barros

%%%%%%%%%%%%%%%%%
% BEGIN IMPORTS %
%%%%%%%%%%%%%%%%%
\RequirePackage{amsmath}
\documentclass[runningheads]{llncs}
\usepackage{indentfirst}
\usepackage{cite}
\usepackage{mathtools}
\usepackage{enumerate}
\usepackage{optidef}
\usepackage{subfigure}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{todonotes}

\newcommand{\SubItem}[1]{{\setlength\itemindent{15pt} \item[-] #1}}
%%%%%%%%%%%%%%%
% END IMPORTS %
%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%
% BEGIN DOCUMENT %
%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%
% BEGIN HEADER %
%%%%%%%%%%%%%%%%
\title {Hives: File Survivability in P2P using Probabilistic Swarm Guidance
\thanks{This work has the support of the project MYRG2016-00097-FST of the University of Macau; by the Portuguese Fundação para a Ciência e a Tecnologia (FCT) through Institute for Systems and Robotics (ISR), under Laboratory for Robotics and Engineering Systems (LARSyS) project UID/EEA/50009/2019.}
}
\titlerunning{Hives}
\author{Francisco Barros, Daniel Silvestre \and Carlos Silvestre}
\authorrunning{F. Barros et al.}
\institute{Instituto Superior Técnico - Taguspark\newline Av. Prof. Doutor Cavaco Silva, 2744-016 Porto Salvo, Portugal
\email{fbarros@isr.ist.utl.pt, dsilvestre@isr.ist.utl.pt, csilvestre@umac.mo}\newline
\url{www.tecnico.ulisboa.pt}
}
\maketitle
%%%%%%%%%%%%%%
% END HEADER %
%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
% BEGIN ABSTRACT %
%%%%%%%%%%%%%%%%%%
\begin{abstract}
Peer-to-Peer (P2P) systems have emerged as a potential choice to build large scale distributed storage systems, at a fraction of the cost of the alternative cloud approaches, which have better quality of service guarantees. We survey  distributed file systems, P2P overlays, cloud-assisted P2P protocols, and erasure-code algorithms. We then draft a solution for the problem of creating a P2P overlay to be used on a cloud-assisted P2P backup system that uses probabilistic swarm guidance and aims to ensure file durability. We anticipate that our solution will have high network overhead, in order to provide good self-healing properties to the files stored in the system.

\begin{keywords}Agents-based Systems; Cooperative Control; Peer-to-Peer; Cloud Storage; Distributed control; File Availability; Swarm Guidance;\end{keywords}
\end{abstract}
%%%%%%%%%%%%%%%%
% END ABSTRACT %
%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BEGIN TABLE OF CONTENTS %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{tocdepth}{3}
\tableofcontents
%%%%%%%%%%%%%%%%%%%%%%%%%
% END TABLE OF CONTENTS %
%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%
% BEGIN INTRODUCTION %
%%%%%%%%%%%%%%%%%%%%%%
\newpage\section{Introduction}\label{sec:intro}

\subsection{Problem Description}
With the growth of the internet and the emergence of distributed systems, two large-scale computing paradigms have gained popularity due to their promise of virtually unlimited scalability. On the one hand, we have Peer-to-Peer (P2P) networking, which can be defined as a group of equally privileged peers, who contribute with a portion of their resources, to achieve common goals. These networks are popular among file sharing and streaming applications due to their self-organized behavior, lack of centralization and, low-cost. On the other hand, Cloud platforms offer unmatched, on-demand, self-service, availability, and reliability, at a higher cost, and are currently trendy, with companies such as Amazon, Google, and Microsoft offering various ITaaS products to individuals and organizations alike. Cloud-based systems are centralized architectures, in which a large number of computers are clustered and managed by master entities, which possibly, become bottlenecks. Both paradigms can be used to deploy distributed file-storage or file-backup applications; although P2P implementations are cheaper for both companies and their clients, these have a hard-time achieving availability levels seen in Cloud implementations. P2P systems also have a higher inherent risk of permanent file loss, making them somewhat unappealing for clients.

\subsection{Frequent approach}
P2P research often focuses on optimizing the overlay topology to provide load-balancing, read/write efficiency, and partition avoidance, implicitly assuming that reliable overlays provide reliable systems, in the case of distributed storage systems, replication or erasure coding is usually written on top of the P2P protocol to ensure durability. The most common approach for distributed storage systems, however, is done on the cloud using highly available machines, with expensive file or block-level replication, continuously monitored by failure detection entities to ensure the replication level is always above some threshold; While effective, the latest architecture is very costly and inefficient. Finally, there have also been some attempts of transparently integrating Cloud Systems into P2P networks, e.g., Cloudcast \cite{cloudcast}, and vice-versa, e.g., Spotify\cite{spotify} and Wuala\cite{wuala}. To the best of our knowledge, there is no system using PSG as a way of simultaneously deciding data routes, failure-detection, load-balancing, and, thus, file survivability in distributed storage systems.

\subsection{Our approach}
The focus of this thesis is to create a distributed backup system. Probabilistic Swarm Guidance (PSG) and Markov Chain theories will be used, along with erasure coding. We hope not to lose the files regardless of the amount of churn\footnote{Property of P2P systems, which regards peers joining or leaving a P2P network} or other experienced faults. Furthermore, to boost the availability and reliability files, cloud servers might be sporadically used to assist the P2P networks when these are facing critical conditions. The main difference between our approach and the frequent ones is that we use a layered solution, where a typical client-server approach facilitates lookup operations and provides system-wide but file durability, load-balancing, and failure detection is the responsibility of multiple P2P overlays specifically tailored for backing up files.

\subsection{Proposal Goals}\label{subsec:intro}
This proposal seeks to address the problem of file survivability in P2P networks; our primary goal is to design and evaluate a P2P overlay that uses probabilistic swarm guidance and erasure-coding as a mean to provide file survivability. Our secondary goal is to integrate instances of this overlay on a broader centralized system that provides fast look-up operations and increases availability and reliability by making connections to the cloud when needed. Steps include:

\begin{itemize}
    \item Identify a steady-state, $Q$, providing optimal robustness and load-balancing
    \item Identify a transition matrix, $M$, that allows peers to achieve $Q$ collectively
    \item Optimize $M$ with respect to peer connectivity degree
    \item Optimize updates to $M$ as overlay topology changes over time
    \item Implement a replication model that exploits the properties of the $M$
    \item Evaluate solution performance in a Simulation or on in real life scenario
\end{itemize}
%%%%%%%%%%%%%%%%%%%%
% END INTRODUCTION %
%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%
% BEGIN RELATED WORK %
%%%%%%%%%%%%%%%%%%%%%%
\newpage\section{Distributed File Systems}\label{sec:distributed-file-systems}
Distributed file system (DFS) enables individuals and organizations to store, access, and secure data on possibly remote locations, as they would their local machines. It is common practice to do file-level or block-level, but it is rare to use erasure-coding. The choice depends on the solution requirements and the broadness of the system. For example, block replication allows parallel execution of applications using MapReduce algorithms, and because of that, Google File System\cite{gfs} (GFS) uses block-level replication. We present two different implementations running on commodity hardware and focus on their architecture, advantages, or disadvantages. Before that, it is essential to understand some desired characteristics of a DFS. In general, distributed systems of any kind should be \textbf{\textit{dependable}}, meaning that they should be able to avoid service failures that are more frequent and more severe than is acceptable. To be dependable is to be ready to provide the correct service (\textbf{\textit{availability}}), in a continuous manner (\textbf{\textit{reliability}}), with absence of catastrophic consequences to clients (\textbf{\textit{safety}}), e.g., losing a file, with no improper system alterations (\textbf{\textit{integrity}}) and, finally, to be able to undergo modifications and repairs at any time (\textbf{\textit{maintainability}}). Some of the features that contribute to the above characteristics are the following: \textbf{\textit{load-Balancing}} is the process of balancing communication, processing, and storage overhead among all nodes of the system. It helps to avoid bottlenecks, increasing operational performance, and helps to prevent catastrophic failures. Prevention of failures is also achieved through \textbf{\textit{fault tolerance}}, which enables a system to continue operating, possibly at a reduced level,  rather  than failing completely, when some part of it fails, to this end, some sort of \textbf{\textit{machine redundancy}} and \textbf{\textit{data redundancy}} may be important. As the amount of data passing in the network, being processed or stored in the system grows, or the number of clients using it increases, the capacity of a system to maintain its service without, or with little degradation, is called \textbf{\textit{scalability}}, it depends on the implementation of the system, and as a rule of thumb, centralized solutions are less scalable.

\subsection{Google File System}
GFS wants to provide efficient and reliable access to data using clusters located in geographically spread data-centers. In particular, GFS aims to provide high data throughput, low latency, and reliability in the face of individual server failures. Because GFS model considers machine and network faults as being the norm, as is, nowadays typical. GFS serves as inspiration for a massively adopted open-source project called Hadoop Distributed File System\cite{hadoop}; we will not discuss it here because it holds many similarities to GFS with key differences being the approach to security management. Based on the author's observation that once written, files on google services, are only read, often sequentially, with random writes being practically non-existent, GFS chooses to optimize throughput over latency, appends over random writes and deliberately skips data block caching. GFS clusters consists of a single master and multiple chunk-servers. The Master maintains a mapping from files to chunks, the current location of chunks, and is responsible for failure detection over the chunk-servers as well as chunk-migration between them. Clients communicate, for reads and writes, with the Master for metadata operations and directly with the chunk-servers for data-bearing operations. A read operation involves obtaining chunk handles and locations from the Master and then retrieving the chunks from one of the many available chunk-severs. For writes, the client splits the file into 64MB chunks and asks the Master to assign them an identifier, and then the client uploads his chunks to the chunk-servers indicated by the Master. GFS has proven its qualities in supporting large-scale data processing. However, small files have shown to lead to overloads on chunk-servers holding them because chunks have a fixed large value size of 64MB. The reasoning such substantial size value is to reduce network overhead, reduce the number of accesses to the Master, and reduce memory used at the Master due to mappings. Concerning our proposal, since convergence to a desired steady-state is likely better achieved when more parts exist on the P2P network, we might consider using file replication rather than erasure-coding when files are small.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{images/gfs_paper.png}
\caption{GFS Architecture}
\label{fig:gfs_arch}
\end{figure}

\subsection{Ceph File System}

\begin{figure}[t]
\centering
\includegraphics[width=0.6\textwidth]{images/cephfs.png}
\caption{CFS Architecture}
\label{fig:cfs_arch}
\end{figure}

Ceph \cite{ceph} is an open-source system that aims to deliver reliable, autonomous, distributed object, block, and file storage that is self-healing, self-managing, and has no single point of failure. The base architectural component of Ceph is the RADOS object store. All clients' reads and writes to the system are represented as objects, irrespective of the objects' original data types. RADOS is a single logical entity composed of many storage clusters. Ceph architecture is sophisticated, so, we summarize the main components. Inside a storage cluster, we find four types of logical machines, storage devices, abstracted with a layer called \textit{object software daemon} (OSD), \textit{monitors}, \textit{managers}, and \textit{metadata servers}. Metadata servers contain information used for POSIX semantics, e.g., file owner or last accessed timestamps. A small number of monitors maintain a master copy of the storage cluster map with its current state. Monitors use Paxos to decide on the state of the cluster. Managers maintain detailed information about placement groups, process and host metadata. Finally, OSD store data on behalf of clients. Additionally, OSD utilize their nodes' resources to perform replication, erasure coding, load-balancing, recovery, monitoring, and reporting functions. Each Storage Cluster as anywhere from dozens to thousands of these OSDs. Ceph's innovation is that OSD within the same \textit{placement group}, within a cluster, are organized in a P2P fashion and are capable of autonomously carrying out recovery tasks. Placement groups are fragments of a logical \textit{pool}, and in turn, pools are logical, dynamic partitions that define among other things, how much and which type of replication is done to objects that belong to it. When one OSD in a placement group suspects another as left or joined the cluster, it consults a Monitor to obtain an up to date cluster map. After running the CRUSH algorithm\cite{crush} over the cluster map, it is possible that the OSD will offload some of its content to another OSD. Clients also use CRUSH to perform reads and writes to the system. To perform a write operation, for example, a client connects to a pool in the storage cluster and runs CRUSH with a cluster map retrieved from a Monitor. The result of the operation gives the client information on the placement group of the data he wishes to upload as well as the OSD he should contact to complete his request. When the target OSD receives the request, it takes the object identifier, pool name, and the cluster map and uses CRUSH, to discover the number of replicas that it should store and to which secondary OSDs he must replicate the write. The operation is completed when the primary OSD, receives acknowledgments from the remaining secondary OSD and acknowledges back to the client. Because operations runs independently on clients and OSDs, there is no need to have the monitor constantly updating cluster to object mappings. Ceph is proof that DFS can reliably be implemented using P2P behavior. Ceph OSDs perform a lot of self-monitoring and management operations and in a decentralized fashion while being highly dependable\cite{ceph_benchmarks}; we hope to be able to replicate these achievements in our approach.

\section{P2P Overlays}\label{sec:p2p-overlays}

\begin{figure}[t]
    \centering
    \subfigure{\label{fig:iplayer}\includegraphics[width=0.35\textwidth, clip=true]{images/ip-layer.png}}
    \hspace{0.2\textwidth}
    \subfigure{\label{fig:overlay}\includegraphics[width=0.35\textwidth, clip=true]{images/overlay-layer.png}}
    \caption{P2P Network Diagrams: IP layer \textit{vs.} One possible overlay abstraction}
    \label{fig:network_diagrams}
\end{figure}

In large-scale P2P systems, it is unfeasible and even undesirable for each peer in the network to know and explicitly interact with every other node connecting it to other peers. In this regard, a P2P overlay is a logical network that abstracts the physical network underneath it, typically IP-based, and where, single-hop edges represent links between pairs of peers, as depicted in Fig. \ref{fig:network_diagrams}. We define some properties and technical jargon related to overlays and graphs that help us understand the research we survey in the next subsections. An overlay is said to be \textbf{\textit{connected}} if there is a path that allows any pair of peers $(i, j)$ to communicate with each other, i.e., there is no partitioning and no peer is isolated in the system. The \textbf{\textit{degree}} of a peer is the total number of connections established between a peer \textit{i} and other peers. We can divide the degree into \textit{in-degree} and \textit{out-degree}, i.e., the number of channels a peer \textit{i} has, through which it can only receive data or send data, respectively. When all peers have the same degree, the overlay is said to be \textbf{\textit{regular}} or \textbf{\textit{symmetric}}. We can use the \textbf{\textit{degree distribution}} to evaluate the robustness of an overlay since through it; it is possible to detect \textit{weakly connected peers} and \textit{massively connected hubs}, i.e., peers with very high degree. Hubs may provide the overlay with resistance against random damage and possibly speed-up lookup operations in unstructured overlays that use biased searching; however, hub failures will have significant impacts on the connectivity of the overlay, severely damaging performance or even halting the system \cite{webdragons, controlling_the_hubs}. Peer degrees are also indicators of fair work distribution among peers. \textbf{\textit{Network diameter}} is the number of links that compose the longest of all the shortest paths between any two peers $(i, j)$. Knowing the length of all shortest paths between all possible pairs of peers allows us to extract the \textbf{\textit{average path length}} and derive how messages, on average, will be relayed on the overlay to contact a stranger. Still regarding distances, the path stretch is the ratio between the number of links a message has to traverse, between any two peers, in the underlying network and the overlay network. \textbf{\textit{Clustering}} directly affects connectivity and network diameter; we can measure it using the \textbf{\textit{clustering coefficient}}. This coefficient represents the percentage of neighbors a peer \textit{i} has, who are also neighbors among themselves. Like peers with high degrees, high clustering coefficients indicate the increased chance of partitioning in the system in the event of massive peer failures and \textit{churn}. Furthermore, it may indicate, in gossip-based protocols, bandwidth overhead due to redundant communications in the cluster, but has the advantage of making lookups faster even when the network is experiencing heavy load, e.g., flash crowd scenarios. Another two terms that often appear in literature are the \textbf{\textit{small-world}} and the \textbf{\textit{power-law}} properties. The small-world property is an umbrella term for a system with a high clustering coefficient and low average path length, yet most peers are not direct neighbors of each other. The power-law property means that there is non-uniform distribution influence in the overlay, e.g., some peers have more responsibilities or perks because they have higher capacities than the rest.

\subsection{Structured Overlays}
Structured overlay ensures peer placement follows rigid rules in order to speed up lookup operations, commonly using Distributed Hash Tables (DHT) or Tree implementations. However, for this reason, these overlays also have higher maintenance costs, making them less ideal for highly dynamic environments.

\subsubsection{Kademlia}\cite{kademlia} is fully decentralized and designed for key-value storage systems, and according to the authors, combines provable consistency, performance, latency-minimizing routing, and symmetric topology. Kademlia peer-identifiers and data-keys are built as in Chord\cite{chord}, using consistent hashing. Inserts and lookups on the overlay are unidirectional, according to the distance between two identifiers, calculated using XOR. The unidirectionality allows caching to be done along lookup paths, alleviating hot spots. Each peer in the overlay maintains a binary tree, routing table, whose leaves are lists of peers, called k-buckets, at distances $2^{x}$ to $2^{x+1}$, $x \in\hspace{1mm}\mathclose[0,160\mathclose]$ from itself, sorted according to the least recently seen policy. As a peer receives messages, if the sender is a new acquaintance, that sender is placed on the proper k-bucket. If a replacement is required, then the least seen peer will be evicted, but only if that peer fails to respond to a ping. This policy helps in the defense against attacks where malicious entities flood the network with new dummy peers. By preferring old acquaintances, Kademlia seeks to enhance the stability of the overlay based on the observation that the longer a peer remains connected to the network, the higher the probability that it will remain connected at least another hour\cite{ssaroiu:msp2pfss}. The XOR metric gives Kademlia an advantage over other DHT-based implementations by making routing tables less rigid and by allowing peers to learn useful routing information from messages they receive. K-buckets allow routing to be done around failed nodes, providing increased churn resistance. We note that Kademlia does not implement an effective mechanism to keep dated entries out of a peer's k-buckets, meaning that the longer a peer stays offline, the worse is k-buckets are when he returns. The standard implementation only removes dated entries when the peer contacts another and obtains no response;

\subsubsection{Self-Chord}\cite{selfchord} is a bio-inspired overlay designed for cloud or grid computing architectures. Its foundations are that of the standard Chord, both in terms of identifier generation and the way peers connect, i.e., in ring-like shapes. Self-Chord a few key differences, however, which result from having \textit{ant} agents independently roaming the overlay but collaboratively re-arranging resource location, i.e., data placement is not based solely on the numerical-space relation between data and placement peers. The rearrangement improves lookup operation speed by clustering similar items around neighboring nodes and provides some churn resistance. Other advantages include less overlay maintenance overhead since when a peer joins or leaves the network, ants will autonomously and eventually distribute data appropriately; While redistributing data, Ants also ensure load-balancing, thus improving scalability and robustness since individual peer failures are less likely to lead to massive file loss. According to the authors, the behavior of the ants ensures that even under highly dynamic, unfavorable conditions, rearrangement, and discovery of data items takes only logarithmic time. Bio-inspired systems like Self-Chord, diminish or eliminate some of the inherent disadvantages associated with structured or unstructured overlays. In these, simple agents often accomplish complex behavior that would otherwise require time or space consuming algorithms, often with high code complexity. The downside of bio-inspired overlays is that the results of agent actions are not always easy to evaluate or predict. In our proposal, we, too, seek to create a system that employs autonomous, self-healing, and self-organizing behaviors.

\subsection{Unstructured Overlays}
Unstructured overlays usually disseminate information in a gossip or broadcasting fashion; lookup operations are slower than on structured overlays, but overlay maintenance is often straightforward. Because peer placement is arbitrary, they tend to provide better scalability and a higher degree of resilience in the advent of failures.

\subsubsection{Gia}\cite{gia} seeks to overcome the drawbacks of Gnutella\cite{gnutella-rfc}, which was the first decentralized, unstructured P2P protocol. Gnutella's main issues were the lack of scalability, as resource discovery was made with flooding, and how easily some peers became overloaded when faced with high rates of aggregate queries. Gia proposes the use of super-nodes, which are nowadays also part of the Gnutella protocol. The super-nodes receive and route queries to peers holding data. Super-node selection and the construction of the topology around them is dynamic. Gia uses random walks, both to alter the topology as well as perform lookup operations. Random-walks alone are less likely to find appropriate lookup responses unless they are biased to high-degree peers, which in turn can make peer overloading frequent. To solve the issue, Gia implements a topology adaptation that puts most peers within reach of high capacity peers, while simultaneously ensuring that they can handle the incoming requests. Lastly, all peers keep pointers to data items kept by their immediate one-hop neighbors to help guiding queries in the right direction. The algorithm Gia uses to ensure high-capacity-peers are also high-degree ones depends on a satisfaction function autonomously executed by each peer, which returns a value $s\in\mathclose[0,1\mathclose]$. As long as $s<1$, the peer takes the initiative of calling another random peer, preferring those whose capacity is better than his. During the handshake, any of the intervenients may abort, based on their capacity and the degrees of their neighbors. The callee accepts the caller whenever he does not know enough peers or the caller as more capacity than at least one of his neighbors; to avoid disconnecting poorly connected peers, the callee will replace the highest capacity peer whose capacity is smaller than that of the caller. In order to avoid hot-spots or overloading of peers, a peer is only allowed to send requests to a neighbor if that neighbor has explicitly given him one Token representing one request that neighbor is willing to accept; Each peer allocates tokens at the rate at which they can answer requests. The results show that Gia manages to reduce network overhead, as expected since it does not use flooding, but is also up to five orders of magnitude faster than Gnutella performing lookups. Gia successfully promotes optimal performance and longevity of the system through continuous, peer carried optimizations. However, we identify one fundamental problem with Gia, related to the systems attempt to load-balance super-peers and implicit free-rider avoidance\footnote{Peers who consume more community resources than they contribute with.}; According to their capacity, peers receive tokens from their neighbors, hence decreasing the number of tokens received by low-capacity peers and, thus, system usability.

\subsubsection{BlatAnt}\cite{blatant} is a bio-inspired overlay designed for grid computing architectures where resource discovery needs to be efficient; BlatAnt focuses solely on network bounded-diameter optimization as means of minimizing network overhead and lookup latency, using swarm intelligence to support flood-like discovery protocols. Like in Self-Chord, ant agents optimize and maintain the overlay; conversely, the ants do not change the location of data items, but instead reorganize peer connections in such a way that the global overlay uses as little of them as possible. The idea is that by doing so, the average number of hops, i.e., average path length, required to obtain a data item from a lookup will be smaller. BlatAnt also uses local index caching to improve efficiency further; The authors argue that local caches, as an alternative to semantic clustering such as the ones used in Self-Chord, are better for self-organized overlays where a stable topology can not be guaranteed. The overlay management can be viewed in three major components. The first component are the \textit{peers} themselves. Each peer keeps two structures, a fixed-size $\alpha$-table, i.e., a partial view of the overlay retaining neighborhood information used to evaluate the redundant connections or the need for new ones, and, a neighborhood-set \textit{N}, containing peer identifiers. Peers contribute to the optimization by rearranging local connections according to the connection rule, which reduces the diameter of the overlay, and disconnection rule, which discards redundant connections. The second component are the ants, which have multiple species; \textit{discovery ants} are randomly spawned by peers and live for a limited time. They wander across the overlay, collecting information about its topology and update the $\alpha$-tables of peers they meet along the way. \textit{Construction ants} act as bootstrappers to the system. When a new peer \textit{i} wants to connect to a peer \textit{j}, he sends one of these ants, if \textit{j} cannot establish the connection because he would violate a degree constraint, he forwards the ant to his lowest-degree neighbor. When a \textit{j'} accepts the ant, he sends it back to \textit{i}, and the procedure complete, i.e., they are now on each others' neighborhood-sets. \textit{Optimization ants} establish connections according to the connection rule. In this case, a peer \textit{i} wanting to connect to peer \textit{j} sends him this ant, and \textit{j} only accepts or refuses the ant. If he accepts, he sends the ant back to \textit{i}. \textit{Unlink ants} remove existing connections between peers because of the disconnection rule applies or because a peer wants to leave the overlay. When this ant arrives at its destination, it removes all sender's information from the $\alpha$-table and the neighborhood-set. \textit{Update Neighbors Ants} are spawned by a peer whenever he establishes or tears-down a connection with some other. These ants visit all of that peer's neighbors and update his information on their respective $\alpha$-table. Finally, \textit{Ping Ants} are periodically exchanged between peers to keep their connections alive in low traffic situations. The last component are \textit{pheromone trails}, which evaporate overtime. A trail is a value assigned to a connection between peers, whenever an ant or query, walks over that connection, they increase the pheromone concentration on both ends. Discovery ants will tend to follow paths with less pheromone concentration, thus incentivizing full network coverage during the exploration. When a peer detects that for a given neighbor, its pheromone concentration has wholly evaporated, that neighbor is assumed to have left the network without warning. Eventually, each peer who neighbored the disconnected peer will independently initiate a recovery protocol by sending construction ants to the neighbors of the disconnected peer, reorganizing the overlay, and avoiding network partitioning. Thus pheromone trails provide seamless error resolution. BlatAnt quickly converges to stable overlays with bounded-diameter, even in very dynamic conditions, resulting in faster lookups due to a decrease in flood messages and also due to caching. Note that BlatAnt could also leverage random walks such as the ones used in Gia for even less network overhead. BlatAnt also introduces optimizations over caching procedures; we do not review them here, because they are based on complex profile similarities and caching is out of the scope of our proposal.

\section{Membership Management Frameworks}\label{sec:membership-management}
Gossip-based protocols are well known for their usability to solve problems like database replication, failure detection, and resource-monitoring. We present two frameworks used for membership management that ensure peers keep up to date partial views of large-scale, dynamic networks, built on unstructured overlays using such protocols. Just like we mentioned in section \ref{sec:p2p-overlays}, keeping a view of all peers in the system is often not a solution. Another fundamental issue in P2P is how to avoid partitioning. The following alternatives are both scalable, robust, and decentralized solutions to both these problems. They gift peers with autonomous capabilities regarding self-organization and overlay healing.

\subsection{Cyclon} Cyclon\cite{cyclon} is useable even in highly dynamic environments, providing peer degree symmetry, low diameter, low clustering, resilience to churn, and massive node failures. The focus of the authors was to provide a lightweight and simple protocol. It consists of having each peer keeping an ever-changing, partial view, with fixed-size \textit{c}, of the network in a structure called \textit{neighbors}. Periodically, independently and asynchronously, a peer contacts a random neighbor to exchange acquaintances. This process is called \textit{shuffling}. During a shuffle, a peer \textit{i}, first increments the age of all his known neighbors by one. Then, selects the oldest of all his neighbors, \textit{j}, and $l-1$ other random neighbors, forming \textit{s}. Then \textit{i} replaces \textit{j}'s network address by his own and sets his age to zero, in \textit{s}. After that, \textit{i} sends \textit{s} to \textit{j} and waits for \textit{j} to reply with \textit{s'}. Unlike \textit{s}, \textit{s'} is composed of a purely random subset of \textit{j}'s neighbors, without any age modifications. Upon reception of subsets \textit{s} and \textit{s'}, \textit{j} and \textit{i}, respectively, update their \textit{neighbors} by first using any empty slots in their partial views and then by replacing entries which they sent to the other, i.e., if \textit{i} has no more slots, he replaces, in its \textit{neighbors} structure, the entries that he sent in \textit{s} to \textit{j}, with the ones he received in \textit{s'} from \textit{j}. Note that, after \textit{i} initiates a shuffle with \textit{j}, \textit{i} becomes \textit{j}'s neighbor, but \textit{j} is no longer a neighbor to \textit{i}, effectively reversing neighboring relation between both peers\footnote{Cyclon links are not bidirectional, conversely to the majority of protocols.}. The age is essential in the shuffling algorithm, for two reasons. First, it limits the lifetime of each peer in neighboring structures, which globally bounds the number of existing pointers to them. Secondly, it also limits the time each peers' addresses are passed around until they are selected as shuffling targets, resulting in a more up-to-date overlay as well as uniform distribution of each peers' addresses over the network. When a peer leaves the overlay for any reason, the remaining peers may have to remove him from their \textit{neighbors} structure. Many authors argue that timely removal is fundamental for the robustness of the overlay, Cyclon uses a reactive pessimistic policy that works as follows: Whenever a peer \textit{i} contacts \textit{j} for shuffling and obtains no response it assumes \textit{j} is disconnected and removes it from his \textit{neighbors}. Since the time for \textit{i} to contact \textit{j} is bounded by the age property, detection is accelerated, which is a property Gia does not have.

Cyclon simulations show that the average path length and clustering coefficient, for various configurations, converged to values similar to those found in random graphs, i.e., converged to small-diameter topologies with low clustering. Gossip-based protocols often have high clustering, which is undesirable both in terms of robustness and overhead. Another exciting result of Cyclon is that the average path length increased logarithmically, and clustering decreased exponentially, as the number of peers in the network increased, hence demonstrating scalability and increased robustness. Noting this property, the authors propose a join method that does not disrupt the randomness of the obtained overlays. Whenever \textit{i} wishes to join the overlay, he contacts one peer \textit{j} already in the overlay who initiates \textit{c} random-walks with time-to-live (TTL) equal to the average path length of the overlay. The peer \textit{k} where the random-walk ends, replaces one of his \textit{neighbors} entries with \textit{i} network address, setting \textit{i} age set to zero and sends the replaced entry to \textit{i}. Note that even if some of the random walks do not complete due to byzantine failures, \textit{i} will remain connected to the overlay and will eventually find new acquaintances. Cyclon as no apparent downsides other than the one where too few peers in the system may cause it to be under performant due to clustering effects, but this is expected in other solutions too. We note that in a certain way, this framework relates to BlatAnt since it implicitly bounds the diameter of the network.

\subsection{Newscast}
In Newscast \cite{newscast-computing}, all peers proactively exchange, timestamped, information with each other, including not only neighboring information but also app-specific information, allowing for simplified implementation of aggregation algorithms, i.e., finding statistics regarding for example network size. Newscast is thus responsible for both membership management as well as information dissemination. Within each Newscast peer, there are two types of entities. Those who run the actual newscast protocol, are called \textit{corespondents}. Those who run the distributed application are called \textit{agents}. \textit{Correspondents} all run the same instance of the newscast protocol. \textit{Agents} are not required to run the same distributed application. Each \textit{agent} has one or more \textit{correspondents}; this responsibility separation does not explicitly exist in Cyclon. Each \textit{agent} implements an interface with two functions \textit{getNews()} and \textit{newsUpdate(news[])}. The \textit{correspondent} uses the former to request news from their \textit{agent}, and the latter to deliver app-specific news collected from other peers' \textit{correspondents} in the network. Each \textit{correspondent} as a fixed-size news cache of size \textit{c} and periodically exchange news with each other has followed: request news to its \textit{agent}, timestamp them along with the local time, and IP-address of the peer, then store the news in a cache entry. Afterward, it selects another peer's IP address running the same type of \textit{correspondent}, as available in his cache. Both \textit{correspondents} exchange the entirety of their caches and pass the merged cache with $2c+1$ entries to their respective \textit{agents} before discarding the oldest entries, after timestamp normalization, down to \textit{c} and storing the results themselves. The timestamp normalization is not a clock-synchronization process and has some inaccuracy, but as long as transmission times between two peers are not too big, there should be no problem. During the discarding process, the algorithm ensures that there is at most one news item per \textit{agent} in the cache.

Newscast as a slight edge over Cyclon, due to graciously accounting for aggregation functions in its native protocol. Similarly, inactive peers are eventually forgotten due to the timestamp property, but we believe that Cyclon has several significant advantages. These include: the resulting overlays of Cyclon have better randomness due to its shuffling-based algorithm, whereas Newscast and other gossip-based management frameworks, seem to have small-world properties according to previous research \cite{eval-gossip-based}. Also, Cyclon uses logical timestamps; hence, no clock synchronization is required, not even a relaxed one. Newly joined peers' cache initialization is based on a regular news exchange with one or more peers who are already members of the overlay. In contrast, Cyclon uses \textit{c} random-walks exchanging exactly one cache entry with possibly different peers, which in turn helps to maintain overlay randomness; finally, while Newscast managed to achieve their goals of providing a robust, scalable, adaptive and lightweight solution, Cyclon exhibits less network overhead and can easily be extended to perform aggregation.

\section{Cloud-Assisted P2P Networks}\label{sec:ca-networks}

Many academic and commercial projects have been suggested and used over the years where cloud and other centralized architectures are partly assisted by P2P networks; In these systems, peers are usually clients of the service, who help to decrease the load on the central system, hence reducing its cost. Examples include Spotify and Wuala until approximately five years ago. However, these approaches are still prevalent in streaming and online gaming services. Blizzard Activision uses their player base to help distribute installers and patches in a P2P fashion, and Digital Extremes uses, in their free-to-play game Warframe, P2P networks in particular, but not all, group missions where individuals are in instances of the game inaccessible by players outside the group. However, only recently, was the alternative experimented, where P2P networks serve the vast majority of the service and are assisted by stable cloud services only to help guarantee some quality of service property of the system under critical situations.

\subsection{Cloudcast}
Cloudcast \cite{cloudcast} is a P2P-assisted cloud architecture that differs from previous approaches because it does not offload the provided service to peers only when service availability is not at risk of being affected. Furthermore, the architecture does not augment P2P systems with elastic computing nodes that perform particular tasks beyond the reach of the P2P network, e.g., bulk-synchronous content distribution. Cloudcast functionality depends only on a passive storage service that transparently integrates into a gossip-based P2P system. The reasoning behind not using elastic computing instances is to eliminate fixed renting costs. Like that, the focus is on minimizing the costs associated with storage and bandwidth. The architecture uses two gossip protocols, one for membership management and another for information dissemination. Key results of the proposal include: i) accesses to the cloud service are bounded regardless of the number of clients in the system; ii) the cloud server only distributes content when few peers are available; iii) the overlay does not suffer from partitioning regardless of the number of peers in the system; iv) the two illustrated use cases have an absurdly low yearly cost when compared to pure cloud approaches; iv) authors imply that most of the expected bill is tied to membership management and not to actual storage costs, suggesting that strategies that adapt to the size of the network could yield better savings.

The passive cloud storage service is a key-value store that can be accessed via GET and PUT operations, but it cannot under any circumstance initiate communications with the system peers. Two problems are identified, \textit{membership management} and \textit{information diffusion}. To solve the first problem, Cloudcast uses the Cyclon protocol to do peer-sampling. From other alternatives, Cyclon was chosen not for its particular inexpensiveness, but because the protocol maintains a random overlay topology that works even during high churn periods and even in the presence of catastrophic failures where up to 80\% of the peers fail. Cyclon properties also guarantee that cloud server has a bounded in-degree, keeping usage cost under control. Finally, the cloud server can easily integrate into Cyclon because the latter does not require the cloud server to initiate any communications, i.e., its active roles can be carried out by peers interacting with it; In this regard, the dummy process carried by the peers occasionally refreshes pointers to the cloud to avoid losing all references to it in the system. To deal with the case where all cloud references are lost due to the dynamicity of the environment and unreliability of the network layer, all peers keep a logical timestamp of the last round they heard about the cloud server updating it whenever they successfully contact it or because one of their a \textit{neighbor} heard about it more recently then them. If after \textit{t} rounds a peer has not updated this timestamp he will create a new cloud reference with probability $p\textsubscript{recovery}$. The second problem is tackled by implementing two gossip algorithms. They are a \textit{rumor-mongering, coin and blind} approach which favors fast news spreading and consists in having a peer \textit{i} periodically forwarding updates he learns about to some other peer \textit{j}, then deciding with probability $p\textsubscript{rumor}$ if he should stop rumoring; And a \textit{anti-entropy, push-pull} approach which guarantees that news are eventually known by all peers by having each peer \textit{i} periodically contacting a random neighbor \textit{j} to exchange updates they know about. All updates to the data are recorded in the cloud server through PUT operations before being rumored. Peers never contact the cloud server for rumor-mongering purposes. We suggest that anti-entropy messages can be piggybacked to the peer-sampling messages, decreasing the number of messages passed in the network; the authors, however, do not implement this optimization.

\subsection{Cyclon-Cloudcast: Adaptive Replica Management}

\begin{algorithm}[t]
\caption{MakeDecision(N\textsubscript{e}), replicaOverlay}
\label{alg:makedecision}
\begin{algorithmic}
    \If {$N\textsubscript{e}\geq S$}
        \State $replicaOverlay.Neighbors.Remove(CloudReference)$\
        \If {$N\textsubscript{e} > R$}
            \State $p\textsubscript{yes} \gets \dfrac{N\textsubscript{e} - R}{N\textsubscript{e}}$
            \State $this.LeaveOverlay(replicaOverlay, p\textsubscript{yes})$
        \State $replicaOverlay.Protocol \gets cyclon$
        \EndIf
    \ElsIf {$C < N\textsubscript{e} < S$}
        \State $N\textsubscript{a} \gets [\dfrac{S(1 + k)}{N\textsubscript{e}} - 1]$
        \State $newNeighbors \gets GetNewNeighbors(this.UnderlyingOverlay, N\textsubscript{a})$
        \State $newNeighbors.Send(this.RandomView(replicaOverlay))$
        \State $replicaOverlay.Neighbors.Add(newNeighbors)$
        \State $replicaOverlay.Protocol \gets cloudcast$
    \ElsIf{$Ne \leq C$}
        \State $N\textsubscript{a} \gets [\dfrac{S(1 + k)}{N\textsubscript{e}} - 1]$
        \State $newNeighbors \gets GetNewNeighbors(this.UnderlyingOverlay, N\textsubscript{a})$
        \State $newNeighbors.Send(this.RandomView(replicaOverlay) \cup CloudReference)$
        \State $replicaOverlay.Neighbors.Add(newNeighbors \cup CloudReference)$
        \State $replicaOverlay.Protocol \gets cloudcast$
    \EndIf
\end{algorithmic}
\end{algorithm}

Following Cloudcast suggestions, H. Kavalionak \textit{et al.}, developed a solution\cite{marriage_of_convinience} that we shall refer to as ARM, with the goal of maintaining an appropriate data replication level, despite churn and, in such a way that peers sharing the same data object are synchronized, i.e., the system should support session guarantees. The main difference between ARM and Cloudcast is that in the latter, the cloud server stores all updates in an always-on passive cloud server that helps with information dissemination, whereas, in the former, the cloud does not participate in the system at all, unless conditions are extreme. Cloudcast monetary cost reductions result from limiting cloud accesses, and ARM effectively reduces those costs further by performing timely switches between Cloudcast and regular Cyclon-based protocols, depending on the size of the network. To estimate that size without centralized or broadcast solutions that could, respectively, lead to bottlenecks or bandwidth waste, ARM periodically runs a monitoring phase whose accuracy dependents only on its duration and whose execution cost depends on the network churn rate, but not on the number of peers in the system. Peer neighboring relations are built naturally from Cyclon peer-sampling, but depending on the results of the aggregation, the cloud server is either removed or kept in the overlay. The decision to add or remove the cloud depends on the following threshold: \textit{Critical (C)} equals the minimum number of replicas required for data recovery plus the number of peer faults the system must support during cloud replication. \textit{Sufficient (S)} depends on the churn-rate and equals \textit{C} plus the number of peers expected between two successive recovery phases. Finally, \textit{Redundant (S)} is an application-specific system parameter. The monitoring phase thus, consists of a fixed number of gossip and idle rounds, allowing a peer to infer the \textit{expected size (N\textsubscript{e})} of the overlay based on Algorithm \ref{alg:makedecision}. After each monitoring phase, peers independently calculate how long they should wait before re-executing the phase. That time depends mostly on \textit{N\textsubscript{e}}, e.g., if the state is below the critical threshold, the monitoring phase will initiate earlier than if it is above the redundant threshold, allowing the system to respond to overlay changes promptly and to keep the overlay size in a range that minimizes overhead but ensures that data does not become unavailable. The authors do not specify how much savings the system was capable of achieving using ARM; however, we can assume it is a substantial value; In Fig. \ref{fig:arm_results}, the plot on top displays the number of peers in the underlying network as a function of time, and the bottom plot shows the in-degree to the cloud server as a function of time, comparing Cloudcast and ARM\footnote{ARM is labeled as "our protocol"}.

\begin{figure}[!ht]
\centering
\includegraphics[width=\textwidth]{images/armresults.PNG}
\caption{Cloud-Server in-degree, Cloudcast \textit{vs.} ARM}
\label{fig:arm_results}
\end{figure}

\section{Data Redundancy}\label{sec:dataredundancy}
In DFS, not losing data is of the utmost importance. Particularly, peer availability in P2P networks is ever-changing and not guaranteed, and thus, availability, and even durability of files are at risk. A \textbf{\textit{durable file}} is one that, once put into the system, is not lost due to failures, whereas availability means that a user can access it promptly. Durability is accomplished by employing file or block-level \textbf{\textit{replication}} or alternatively, using \textbf{\textit{erasure coding}} techniques (\textit{coding} for short). Hybrid approaches are also possible. Replication has the advantage of having a straightforward and less resource-intensive recovery model, on the other hand, coding has a better \textit{expansion factor}, i.e., can provide the same or even increased durability at a lower storage overhead. Because our proposal focuses on the survivability of files in P2P networks built on top of personal computers, using swarm guidance, where resources may be limited, we focus on surveying coding, mentioning raised concerns and inherent disadvantages of this technique.

Two parameters specify some of the most widely used coding algorithms, the number of data symbols \textit{k} to be encoded, and the number of coded symbols \textit{n} to be produced, both assumed to be in a finite field $GF(2^w)$ and these are referred as \textit{(n, k) erasure-codes}. The fundamental idea, is that a file of size $S$ is divided into $k$ equally sized fragments and encode them into $n$ encoded fragments, allowing the original file to recovered from any set of encoded-fragment with count $k$. Systems that use these and other more sophisticated coding are evaluated under some of the following metrics, the \textbf{\textit{repair-bandwidth}}, i.e., the number of bits communicated in the network during normal and repair operations, the \textbf{\textit{disk I/O}} which is the number of bits read from disk during each repair, the \textbf{\textit{repair locality}} which is the number of peers that would be involved in the repair process; Since coding algorithms are slow processes CPU cycles, XOR operation counts and cache misses are metrics often researched as well \cite{fast_coding}, when the main interest is tied with load-balancing and cost savings. We take particular interest in the first metric because, in general, coding may lead to unreasonable bursts in bandwidth consumption when availability requirements, in very dynamic systems, are high \cite{coding-problems}, even for today's standards. Whenever a peer fails, all files he held need to be quickly recovered by some peer who needs to gather enough fragments from possibly many different peers. Such burst in consumption may lead to delays or even failure of the repair process due to physical link capacity between peers, who are involved in the repair process, or even throughput constraints enforced by each peer. When it comes to redundancy in a distributed storage systems, one fundamental question is deciding when to replicate or recover data; this is often called the replica-control problem.

There are two main approaches, reactive and proactive. Reactive approaches are the least complex, and consist of recovering data whenever a failure is detected; they suffer the most from bandwidth bursts, and mitigations to this problem include use of predictive models and thresholds to avoid unnecessary recoveries \cite{lifetime-reactive, efficient-replica-mng-reactive}. Proactive approaches seek to smooth bandwidth consumption by injecting new redundancy data into the network overtime at a fixed-rate \cite{proactive-rep, reliability-without-availability}.

The most widely known coding algorithms belong to the \textit{Maximum Distance Separable} (MDS) class, this class is likely to offer the best reliability-redundancy trade-off. Regardless of the chosen approach, research \cite{network-coding-for-dss} suggests that for coding to be competitive in distributed storage systems, one should seek to minimize these costs, while maximizing redundancy to only the amount necessary to ensure a specific service guarantee. They identify \textit{Minimum Bandwidth Regenerating} (MBS), and all codes in between these two ends of the spectrum as \textit{regenerating codes}, the differences between codes on the spectrum depend on the values such has \textit{n}, \textit{k} and on the implementation of the algorithms themselves. Shokrollahi \textit{et al.} introduces raptor codes \cite{raptor-codes}, which are a linear-time coding and decoding extension of LT codes. LT codes belong to the class of rateless codes, i.e., a potentially infinite sequence of encoded fragments can be generated from a given data source. Furthermore, the original data is recoverable from any subset of the encoded fragments of size equal to or slightly larger than original data size; These rateless code implementations are of particular importance because they are scalable with regards to the machine and network resources,  and fault-tolerant concerning dynamic and heterogeneous network environments. Finally, Zhou \textit{et al.} \cite{fast_coding} perform a study on state of the art techniques that improve coding efficiency through bitmatrix optimization, vectorization, and scheduling and prove that when used in conjunction much better levels of performance can be delivered, e.g., 552.27\% when compared to simple MDS implementations, in particular, the Reed-Solomon algorithm.

\section{Probabilistic Swarm Guidance}\label{sec:psg}
Markov chains describe a sequence of possible events in which the probability of each event depends only on the previous event states, often used to model real-world processes, such as queues of customers arriving at an airport and population growths. Markov processes are the basis for stochastic simulation methods known as Markov Chain Monte Carlo (MCMC), which allow one to perform random sampling over vast state spaces, i.e., computing expectations concerning complex, high dimensional probability distributions. The idea behind MCMC is creating a Markov Chain, which will, over time, tend to an equilibrium that is close to desired density distribution. In robotics and control areas Markov Chains and MCMC are used as the basis foundation for a process known as probabilistic swarm guidance, which gifts autonomous robots with the capability of generating their trajectories independently of each other, in decentralized fashion and without ahead-of-time position allocation, so that sets of robots, known as swarm, converges to the desired distribution shape. Swarm guidance has the advantage over other methods for this problem because robots do not necessarily need to communicate with each other to perform their tasks, even if they could gain from it; their overall distribution can be adapted dynamically to the environment, and any damage to their desired formation is eventually self-repaired. Demonstration of these properties can be found in recent research by B. Açikmeçe \textit{et al.} \cite{psg-mca, psg-caa}, which inspired us to apply swarm guidance principles to P2P networks and file survivability. Boyd et al. \cite{fast_mixing_mc} argue that the most popular MCMC methods, Metropolis-Hastings and Maximum-Degree Chain, that allow the creation of transition matrices, that can then be followed independently by autonomous robots in order to practice swarm guidance behavior are not optimal with respect to mixing rates, i.e.,  these algorithms may not result in matrices that converge in small amount of steps towards the desired density distribution. They propose that the problem of obtaining such matrices can be formulated as a convex optimization problem and prove that, for most cases, the resulting matrices have higher mixing rates. It is reasonable to assume that, concerning our problem in P2P networks, this might open the possibility of imposing additional constraints on the creation of the transition matrix, e.g., bounding the probability of a peer sending a file to some other peer in his hive to increase bandwidth balancing.

%%%%%%%%%%%%%%%%%%%%
% END RELATED WORK %
%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BEGIN SOLUTION PROPOSAL %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage\section{Solution Proposal}\label{sec:proposal}
In this section, we introduce a prototype architecture that targets the use case that inspired to explore the theme of this thesis. We explain it by decomposition.

\subsection{Use Case}
Fundamentally, the idea is that a company, Hives, with dedicated web servers called Hiveminds, provides a platform for registered users to sell storage belonging to their personal computers directly to other registered users. Clients pay a monthly fee directly to Hives based on how much storage space they need. Hiveminds then put together a set of sellers, which constitute a Hive, that serves adequate storage space to the clients. Sellers are selected according to the reputation they earn over time based on their reliability, with a bias towards more reputable sellers. The collected fee is distributed proportionately among Hive members according to their overall space contribution and up time, calculated weekly, for example. The company's revenue comes from keeping a small percentage of the monthly fees. If the client requires continuous availability, rather than durability, he may pay a premium, in which case, inspired on the related work mentioned in section \ref{sec:ca-networks}, cloud storage may be used to help the Hive in meeting the required service guarantees. Hive revenue shares are reduced if their reliability degrades too much.

\subsection{Key notes and Assumptions}
\begin{itemize}
    \item Session handling and payment models are out of the scope of this proposal.
    \item Reputation is static, i.e., they are simulation parameters.\footnote{See goals in Section \ref{sec:intro}}
    \item Message integrity and confidentiality are not at risk.
    \item Sellers are not malicious, e.g., do not perform DoS on other sellers.
    \item Sellers may fail without warning, and some absences may be transient.
    \item Cloud service is abstract, i.e., ranges from local to cloud storage servers.
    \item The storage space purpose is backups, thus write operations are rare.\footnote{Write operations possibly cause old versions to be overwritten}
    \item The storage space is not shared, i.e., there are no concurrent writes.
\end{itemize}

\subsection{Hiveminds - Master Servers}
The Hivemind servers are the backbone of the system; they have to handle registration, login, subscription and payment procedures. When a client wishes to subscribe to a monthly plan, he contacts one Hivemind server at random by accessing his desktop application, and the Hivemind then sets a \textit{usedSpace} variable indicating how much data the Client uploaded into the system to zero. This variable is updated according to the Client's future requests. In Hives File System (Hives), users' files are uniquely identified and have no hierarchy. Hiveminds keep a mapping between the \textit{fileId} and the Hive\footnote{Set of peers S responsible for holding one or more files from one or more clients} that is responsible for storing them. Hive membership is dynamic, and a mapping between the \textit{HiveId} and the Hive members (Workers) is also kept. Note that it is not relevant to know which fragments each Worker in the Hive has; this is important because it diminishes the number of messages sent to Hiveminds and also reduces space overhead required to keep track of file locations. When a Hivemind receives a file upload request from a Client, it finds or creates a suitable Hive to host the data and calculates, if needed, the transition matrix used for PSG within it, before returning all relevant data to the Client, including Workers' addresses. When the Hivemind receives a delete request, it drops all mapping data regarding the respective \textit{fileId}.

\subsection{Clients}
After registration, logging in, and subscription procedures, Clients, can perform four main procedures, which we name and implement using HTTP semantics. In all cases, the Client first retrieves the Hive Workers' addresses. In a GET request, the Client downloads enough fragments from the Hive Workers and reconstructs the file himself. In a DELETE request, the Client first asks the Hivemind to stop tracking efforts, and once he receives an acknowledge, he broadcasts in a best-effort manner a DELETE message to any online worker within that file's Hive. In a POST operation, the Client first obtains permission to upload from the Hivemind; after that, he divides his file into parts, applies an erasure coding algorithm over each them, and uploads the encoded fragments to the workers at random. PUT updates existing files and operate similarly to POST, but whenever possible, try to send the new version to the Hive that contains the previous \textit{versionId}.

\subsection{Workers - Sellers}
Apart from adequately dealing with clients' requests, Workers organize themselves in a P2P fashion within each Hive. One Worker can be in zero or more Hives, and within each Hive, they continuously redistribute encoded file part fragments according to the transition matrix that is calculated by the Hivemind and delivered to them by a Client. In the long run, we expect that a Hive achieves the desired fragment distribution that fairly distributes load while ensuring optimal durability. Constantly exchanging fragments is expected to cause a bandwidth overhead but has the advantage that Clients can upload their fragments to any online peer or peers in the Hive instead of one single entity that may go offline during the upload. Workers will then redistribute the fragment using simple routing rules. This approach does not sacrifice fast lookup operations due to the structured nature of the system using a Hivemind that behaves somewhat like a BitTorrent tracker. The never-ending fragments exchange between peers also facilitates the timely detection of non-transient faults in the Hive, which helps to ensure file durability. Workers piggyback aggregate information to the fragments, including but not limited to, how many parts of a file they have, allowing us to implement a hybrid between a reactive and a proactive system concerning replica control, in hopes of minimizing bandwidth burst on top of already high bandwidth requirements. Fragment exchange may eventually be replaced with ping-like messages to minimize bandwidth cost further, hence the importance of having a fast mixing rate transition matrix. When a Worker suspects that some other Worker on a Hive is faulty for too long, he first contacts a dedicated server, called Keeper, who decides the new Hive membership. The suspecting Worker then individually decides based on previous aggregate information if he should inject new fragments regarding the file into the network if he believes durability is at risk. Whenever a Worker who has been temporarily offline reconnects, he first contacts the master to know what \textit{fileId} is he is no longer responsible for maintaining, allowing him to free space. They also perform this procedure whenever they do not receive a fragment or a ping regarding a \textit{fileId} for a sufficiently long period.

\subsection{Keepers}
Keepers' sole responsibilities are: performing limited hop random walks on the network to gather data that might be used on a Reputation System and to decide new Hive membership on behalf of the Workers who detect faults and possibly on behalf of the Hiveminds.


%%%%%%%%%%%%%%%%%%%%%%%%%
% END SOLUTION PROPOSAL %
%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BEGIN EVALUATION METHODOLOGY %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluation Methodology}\label{sec:methodology}
We will first evaluate the performance of different transition matrix generating algorithms by comparing their theoretical fast mixing property against the number of discrete time steps the matrices take to converge on a simple, cycle-based, locally ran, custom-built simulator. We will select one of these algorithms based on how fast convergence occurs, computing time vs. space complexity, and the possibility of allowing each peer to update their transition matrix autonomously when faced with transient neighbor faults. After this initial step, we will implement a reactive replica-control policy using erasure-coding at each peer and test the durability of files on our custom-built simulator, where we have perfect failure detectors. We are concerned with discovering a good trade-off between storage overhead and durability by using different (n, k) values without caring for any networking aspects. Finally, we will measure bandwidth consumption as well as the robustness of our solution under more realistic simulations by either implement our protocol on well-known P2P Simulation test-bed such has PeerfactSim.KOM\cite{peerfact}, or if time permits it, deploy proof of concept applications on the university's computer cluster for distributed testing.

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END EVALUATION METHODOLOGY %
%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%
% BEGIN WORK SCHEDULE %
%%%%%%%%%%%%%%%%%%%%%%%
\newpage\section{Work Schedule}\label{sec:workschedule}
%%%%%%%%%%%%%%%%%%%%%
% END WORK SCHEDULE %
%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%
% BEGIN CONCLUSIONS %
%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}\label{sec:conclusion}
%%%%%%%%%%%%%%%%%%%
% END CONCLUSIONS %
%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%
% BEGIN REFERENCES %
%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{splncs04}
\bibliography{bibliography}
%%%%%%%%%%%%%%%%%%
% END REFERENCES %
%%%%%%%%%%%%%%%%%%

\end{document}
%%%%%%%%%%%%%%%%
% END DOCUMENT %
%%%%%%%%%%%%%%%%
